{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn.preprocessing as prep\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zhangzhen\nAutoEncoder\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "print(\"AutoEncoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.1698401  -0.06624639]] \n",
      "\n",
      "[[ 0.7266238  -0.02556622]\n",
      " [ 0.8269533   0.94094336]] \n",
      "\n",
      "[[-0.42756602 -0.45622638  0.46571004 -0.5897876   0.26043653  0.26666903\n",
      "   0.08165872  0.20378679  0.3700722  -0.05493122  0.35615778 -0.24716526]\n",
      " [ 0.03058684  0.14769298  0.47950304 -0.5812248   0.30964786 -0.2709414\n",
      "   0.02204543  0.3706919   0.42468882 -0.26162592  0.10810822 -0.12229562]\n",
      " [ 0.28569776  0.24804258  0.16488826  0.14234954  0.35423273  0.26771605\n",
      "  -0.05920851 -0.441086   -0.20098042 -0.07493913 -0.10899445  0.18068445]\n",
      " [-0.56379193 -0.19462979  0.496516    0.09247845 -0.5843429  -0.2950208\n",
      "   0.26738435  0.16739517 -0.50270087 -0.15485126  0.25061792  0.09368908]\n",
      " [-0.3591723   0.16769278 -0.49909198 -0.26201543  0.5462408  -0.5799796\n",
      "   0.5638156   0.05251139  0.43511105  0.24451089 -0.33938935 -0.10266507]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Xavier  美 ['zeɪvɪr]\n",
    "\n",
    "# define xavier initialization function, mean distribution or gauss distribution\n",
    "# mean = 0, var = 2/(dim_in+dim_out) \n",
    "\n",
    "\n",
    "def xavier_init(dim_in, dim_out, constant=1):\n",
    "    \"\"\"\n",
    "    dim_in: dimension of the input tensor \n",
    "    dim_out: dimension of the out tensor \n",
    "    \"\"\"\n",
    "    span = np.sqrt(6/(dim_in + dim_out))\n",
    "    return tf.random_uniform((dim_in, dim_out), minval=-span, maxval=span, dtype=tf.float32)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(xavier_init(1, 2)), \"\\n\")\n",
    "    print(sess.run(xavier_init(2, 2)), \"\\n\")\n",
    "    print(sess.run(xavier_init(5, 12)), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/zhangzhen/gitRepository/AnalyticsVidhya/_tensorflow/MNIST_data/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/zhangzhen/gitRepository/AnalyticsVidhya/_tensorflow/MNIST_data/train-labels-idx1-ubyte.gz\nExtracting /Users/zhangzhen/gitRepository/AnalyticsVidhya/_tensorflow/MNIST_data/t10k-images-idx3-ubyte.gz\nExtracting /Users/zhangzhen/gitRepository/AnalyticsVidhya/_tensorflow/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 0.167803666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0003 cost= 0.112595153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0005 cost= 0.101961227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0007 cost= 0.088240862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0009 cost= 0.095537715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0011 cost= 0.106739216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0013 cost= 0.102885709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0015 cost= 0.096853506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0017 cost= 0.097080449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0019 cost= 0.089853504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cost:0.09154988\n"
     ]
    }
   ],
   "source": [
    "class AdditiveGaussianNoiseAutoEncoder:\n",
    "    \n",
    "    def __init__(self, n_input, n_hidden, transfer_function=tf.nn.softplus, optimizer=tf.train.AdamOptimizer(), scale=0.1):\n",
    "        self.n_input = n_input\n",
    "        self.n_hidden = n_hidden\n",
    "        self.transfer = transfer_function\n",
    "        self.scale = tf.placeholder(tf.float32)\n",
    "        self.training_scale = scale\n",
    "\n",
    "        network_weights = self._initialize_weights()\n",
    "        self.weights = network_weights\n",
    "        \n",
    "        with tf.name_scope(\"input\"):\n",
    "            self.x = tf.placeholder(tf.float32, [None, self.n_input])\n",
    "        \n",
    "        with tf.name_scope(\"hidden\"):\n",
    "            self.hidden = self.transfer(\n",
    "                tf.add(tf.matmul(self.x + scale*tf.random_normal((n_input,)), self.weights['w1']),\n",
    "                       self.weights['b1'])\n",
    "            )\n",
    "        with tf.name_scope(\"output\"):\n",
    "            self.reconstruction = tf.add(tf.matmul(self.hidden, self.weights['w2']), self.weights['b2'])\n",
    "    \n",
    "        with tf.name_scope('loss'):\n",
    "            self.cost = 0.5 * tf.reduce_mean(tf.pow(tf.subtract(self.reconstruction, self.x), 2.0))\n",
    "        \n",
    "        self.optimizer = optimizer.minimize(self.cost)\n",
    "        \n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        all_weights = dict()\n",
    "        all_weights['w1'] = tf.Variable(xavier_init(self.n_input, self.n_hidden))\n",
    "        all_weights['b1'] = tf.Variable(tf.zeros([self.n_hidden], dtype=tf.float32))\n",
    "        \n",
    "        all_weights['w2'] = tf.Variable(tf.zeros([self.n_hidden, self.n_input], dtype=tf.float32))\n",
    "        all_weights['b2'] = tf.Variable(tf.zeros([self.n_input], dtype=tf.float32))\n",
    "        return all_weights\n",
    "\n",
    "    def partial_fit(self, X):\n",
    "        cost, opt = self.sess.run((self.cost, self.optimizer),feed_dict={self.x: X, self.scale: self.training_scale})\n",
    "        return cost\n",
    "    \n",
    "    # loss function\n",
    "    def calc_total_cost(self, X):\n",
    "        return self.sess.run(self.cost, feed_dict={self.x: X, self.scale: self.training_scale})\n",
    "\n",
    "\n",
    "mnist = input_data.read_data_sets('/Users/zhangzhen/gitRepository/AnalyticsVidhya/_tensorflow/MNIST_data', one_hot=True)\n",
    "with tf.Graph().as_default():\n",
    "\n",
    "    def standard_scale(X_train, X_test):\n",
    "            preprocessor = prep.StandardScaler().fit(X_train)\n",
    "            X_train = preprocessor.transform(X_train)\n",
    "            X_test = preprocessor.transform(X_test)\n",
    "            return X_train, X_test\n",
    "    \n",
    "    def get_random_block_from_data(data, batch_size):\n",
    "            start_index = np.random.randint(0, len(data)-batch_size)\n",
    "            return data[start_index:(start_index+batch_size)]\n",
    "\n",
    "    X_train, X_test = standard_scale(mnist.train.images, mnist.test.images)\n",
    "    \n",
    "    n_samples = int(mnist.train.num_examples)        \n",
    "    training_epochs = 20\n",
    "    batch_size = 128\n",
    "    display_step = 2\n",
    "    \n",
    "    autoencoder = AdditiveGaussianNoiseAutoEncoder(n_input=784,\n",
    "                                                   n_hidden=200,\n",
    "                                                   optimizer=tf.train.AdamOptimizer(learning_rate=0.002),\n",
    "                                                   scale=0.01)\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(n_samples/batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_xs = get_random_block_from_data(X_train, batch_size)\n",
    "            # cost = autoencoder.partial_fit(batch_xs)\n",
    "            cost = autoencoder.partial_fit(batch_xs)\n",
    "            avg_cost += cost / n_samples * batch_size \n",
    "        \n",
    "        if epoch % display_step == 0:\n",
    "            print('Epoch:', '%04d' % (epoch+1), 'cost=', '{:.9f}'.format(avg_cost))\n",
    "    print('Total cost:'+str(autoencoder.calc_total_cost(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
